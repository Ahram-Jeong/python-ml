{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 기본 Prompt 구조 이해\n",
    "✅ prompt에는 3가지 종류의 역할(role)이 존재\n",
    "1. User Prompt : 사용자가 LLM 모델에게 전달하는 prompt\n",
    "2. Assistant Prompt : LLM 모델이 응답하는 prompt\n",
    "3. System Prompt : 사용자 Prompt 이전에 정의되는 전제 및 규칙 prompt\n",
    "\n",
    "- System Prompt 예시\n",
    "    - 출력 형태 지정 (ex. json, ppt 등)\n",
    "    - 페르소나(투자전문가, 예술가 등) 및 어조(공손한, 전문적인 등) 설정\n",
    "    - 모델이 지켜야 할 규칙 설정\n",
    "    - 기타 Base가 되는 외부 정보 주입\n",
    "ChatGPT 포함 웬만한 LLM 모델들은 prompt 입력 시, 기본적으로 개발자가 지정해 둔 System Prompt가 붙어서 동작"
   ],
   "id": "6a1525fa9e3a16ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T16:04:14.447611Z",
     "start_time": "2024-07-09T16:04:13.026456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "from getpass import getpass"
   ],
   "id": "7ec1c38bdb582dc0",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T16:07:19.662159Z",
     "start_time": "2024-07-09T16:07:17.800191Z"
    }
   },
   "cell_type": "code",
   "source": "MY_API_KEY = getpass(\"OpenAI API Key >> \")",
   "id": "fd2197a46c83ef9b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T16:07:22.382804Z",
     "start_time": "2024-07-09T16:07:21.236272Z"
    }
   },
   "cell_type": "code",
   "source": "client = OpenAI(api_key = MY_API_KEY)",
   "id": "f68998b634c64c22",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T16:07:25.335370Z",
     "start_time": "2024-07-09T16:07:22.382804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "content = \"당신은 물리학 선생님입니다. 초등학생에게 설명하듯이 아주 쉽고 친근하게 설명해야 합니다.\"\n",
    "completion = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [\n",
    "        {\"role\" : \"system\", \"content\" : content},\n",
    "        {\"role\" : \"user\", \"content\" : \"왜 하늘은 파란색인가요?\"}\n",
    "    ],\n",
    "    temperature = 0\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ],
   "id": "fb0fafa9263c71a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하늘이 파란색인 이유는 바로 '산란' 때문이에요! 태양에서 나오는 빛은 다양한 색깔을 가지고 있는데, 그 중에서도 파란색 빛이 하늘에 가장 많이 흩어지게 되요. 이 파란색 빛이 하늘 곳곳에 흩어지면서 우리 눈에 파란색으로 보이게 되는 거에요. 그래서 하늘은 파란색으로 보이는 거죠!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T16:11:34.492745Z",
     "start_time": "2024-07-09T16:11:31.080362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "content = \"당신은 물리학 선생님입니다. 초등학생에게 설명하듯이 아주 쉽고 친근하게 설명해야 합니다. 왜 하늘은 파란색인가요?\"\n",
    "completion = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [{\"role\" : \"user\", \"content\" : content}],\n",
    "    temperature = 0\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ],
   "id": "391f1f8fe7cdaea1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하늘은 파란색인 이유는 태양빛이 하늘을 통과할 때 빛의 색깔 중 파란색이 가장 많이 흩어지기 때문이에요. 태양빛은 다양한 색깔을 가지고 있는데, 이 중 파란색 빛은 다른 색깔보다 더 짧은 파장을 가지고 있어요. 그래서 파란색 빛은 공기 분자와 충돌할 때 더 많이 흩어지게 되고, 우리 눈에 파란색으로 보이게 되는 거에요. 그래서 하늘은 파란색으로 보이는 거죠!\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Stream 객체 살펴보기\n",
    "- stream = True로 설정 시, 모델이 문장을 모두 완성하여 출력하는 것이 아니라, 각 청크(토큰들의 집합) 별 완성되는 대로 바로 출력"
   ],
   "id": "12d0b21d4fca4117"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T16:16:56.297936Z",
     "start_time": "2024-07-09T16:16:53.266678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stream = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [{\"role\" : \"user\", \"content\" : \"왜 하늘은 파란색인가요?\"}],\n",
    "    temperature = 0,\n",
    "    stream = True\n",
    ")\n",
    "# stream = True 설정 시, 응답 객체가 ChatCompletion이 아닌, ChatCompletionChunk로 반환되고, 각 청크 마다 응답을 실시간으로 받게 됨\n",
    "print(type(stream))\n",
    "print(\"=\" * 30)\n",
    "\n",
    "for i in stream :\n",
    "    # print(i)\n",
    "    content = i.choices[0].delta.content\n",
    "    if content is not None :\n",
    "        print(content, end = \"\")"
   ],
   "id": "b307f3eee999040e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'openai.Stream'>\n",
      "==============================\n",
      "하늘은 파란색으로 보이는 이유는 대기 중의 분자들이 햇빛을 흡수하고 다시 방출할 때 파란색 빛이 가장 많이 방출되기 때문입니다. 태양으로부터 오는 햇빛은 다양한 색상의 빛으로 구성되어 있지만, 대기 중의 분자들이 파란색 빛을 더 많이 흡수하고 방출하기 때문에 하늘은 파란색으로 보이는 것입니다."
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 프롬프트 엔지니어링에서 기본적으로 생각해야 될 점\n",
    "- 생성형 AI 모델의 출력은 입력 값에 대한 의존도가 매우 높음\n",
    "    - 잘 입력한 것 같으나, 원하는 결과가 나오지 않는다면 입력이 모호하거나 응답에 필요한 내용이 빠졌을 수도 있음\n",
    "    - 그게 아닌 경우 모델의 능력으로 해결하기 힘든 요청일 수도 있음\n",
    "- 자연어 질의를 기반으로 하기 때문에 절대적으로 성능이 좋은 prompt가 존재하지 않음\n",
    "    - 성능이 좋다는 것은 사용자가 만족해야 한다는 것인데, 이는 매우 주관적이고 판단하기 어려움\n",
    "    - 정확한 응답이 좋을 수도 있고, 창의적인 응답이 좋을수도 있음 (temperature로 조정 가능)\n",
    "- 즉, 프롬프트 엔지니어링은 Task에 맞는 여러 번의 테스트가 중요하고, 이를 통한 반복적인 개선이 필요"
   ],
   "id": "9b6638675e09c395"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### LLM 모델의 Task에 따른 평가 지표들을 알아보고, 대화 및 Q&A Task에 실제로 적용해보자.\n",
    "#### ✅ 전통적인 Language Model 평가 지표\n",
    "1. MMLU (Massive Multitask Language Understanding)\n",
    "    - 다양한 분야에 대한 질문 후, 정답을 찾아내는 객관식 시험\n",
    "2. HellaSwag\n",
    "    - 문장들을 주고 이어지는 마지막 문장으로 가장 적합한 4개의 문장 중 하나를 고르는 문제\n",
    "#### ✅ 대화 및 Q&A task에 적합한 평가 기법 방식\n",
    "1. Human Based Method : 사람이 평가하는 방법\n",
    "2. Model Based Evaluation : LLM 모델이 평가하는 방법\n",
    "3. Code Based Evaluation : 코드로 평가하는 방법\n",
    "#### 1) Human Based Method\n",
    "- 전문가 블라인드 A/B 테스트\n",
    "- 2가지 모델의 답변 중에서 더 좋은 답변을 선택하는 방법\n",
    "- 명확한 결과로 성능을 판단하기 쉬움\n",
    "- 많은 인력과 그에 따른 비용, 시간이 필요함\n",
    "##### LMSys사 Chatbot Arena\n",
    "- 대표적인 Human Based Method 중 하나로, 동일한 질문에 대해 2개 모델의 답변을 보고 승/패/무 투표 이후에 모델 명을 공개하는 방식\n",
    "- 투표한 결과에 대한 모델들의 랭킹도 확인 가능 (현재까지 140만 번 이상의 테스트 진행)\n",
    "#### 2) Model Based Evaluation\n",
    "고성능(일반적으로 GPT4 이상) strong LLM을 통해 평가하는 방법 (LLM-as-a-judge)\n",
    "- 실제로 사람이 평가하는 것과 굉장히 유사하고 일치율이 높다는 논문 결과들이 나오고 있음\n",
    "##### 평가 방식 3가지\n",
    "1. Pairwise Comparison\n",
    "- 2개의 모델에 같은 질문을 하고, 2개의 답변을 받아 어떤 답변이 좋은지 혹은 무승부인지 출력\n",
    "2. Single Answer Grading\n",
    "- 질문과 답변이 있을 때 점수를 매기는 것\n",
    "3. Reference-Guided Grading\n",
    "- 예시 답변을 주고, 얼마나 유사한 지에 대한 점수를 매기는 것\n",
    "#### 3) Code Based Evaluation\n",
    "- Accuracy, Precision, Recall, F1score 등 일반적인 평가 지표들을 사용\n",
    "- ROUGE : 요약 모델의 성능을 평가하는 지표 (모델이 요약한 내용과 실제 정답 요약본의 일치율을 비교)\n",
    "- BLEU : 번역 모델 평가 지표\n",
    "- Human Based 및 Model Based에 비해 실제 사용자들의 만족과 크게 일치하지는 않음\n",
    "\n",
    "- 참조 논문 : Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena, 2023\n",
    "- 논문 내용으로 LLM 모델의 평가가 사람의 평가와 일치율이 점점 높아지고 있다는 것을 증명 (GPT4의 경우 사람과 85% 수준의 일치율)\n",
    "- 즉, 이는 기계의 판단이 인간의 판단에 도움이 되며, 기계를 통한 자동화된 평가 프로세스 개발이 가능하다는 것을 시사함 (실제로 해당 논문에서 인간은 75%의 사례에서 기계의 판단이 합리적이라 생각했고, 34%의 사례에서 자신의 선택을 바꿀 의향이 있다고 대답 함)"
   ],
   "id": "19ac0ef5b3f1e931"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 위 논문을 참고하여, 대화 및 Q&A에 적용해보자.\n",
    "- gpt-3.5와 gpt-4의 응답을 비교하여 gpt-4o에게 어떤 응답이 더 나은지를 판단하게 함\n",
    "- 평가를 위한 프롬프트는 MT-Bench and Chatbot Arena 논문의 Figure 5 부분 참조  "
   ],
   "id": "e98c0b1b6fd84fb3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T16:34:05.806599Z",
     "start_time": "2024-07-09T16:34:05.788825Z"
    }
   },
   "cell_type": "code",
   "source": "question = \"하늘은 왜 파란색인가요?\"",
   "id": "8c33717ddfd9c623",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T16:35:38.566645Z",
     "start_time": "2024-07-09T16:35:34.364669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# gpt-3.5-turbo\n",
    "completion = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [{\"role\" : \"user\", \"content\" : question}],\n",
    "    temperature = 0\n",
    ")\n",
    "answer_a = completion.choices[0].message.content\n",
    "print(answer_a)"
   ],
   "id": "76a85d88fd7aabfb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하늘이 파란색인 이유는 태양빛이 대기 중의 공기 분자들과 상호 작용하여 발생하는 현상 때문입니다. 태양빛은 다양한 색상의 빛으로 구성되어 있지만, 대기 중의 공기 분자들은 파란색 빛을 더 많이 흡수하고 다른 색상의 빛을 더 많이 반사합니다. 이러한 현상으로 인해 우리가 보는 하늘은 파란색으로 보이게 됩니다.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T16:36:57.728712Z",
     "start_time": "2024-07-09T16:36:43.050085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# gpt-4-turbo\n",
    "completion1 = client.chat.completions.create(\n",
    "    model = \"gpt-4-turbo\",\n",
    "    messages = [{\"role\" : \"user\", \"content\" : question}],\n",
    "    temperature = 0\n",
    ")\n",
    "answer_b = completion1.choices[0].message.content\n",
    "print(answer_b)"
   ],
   "id": "54e8bbe177ab5534",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하늘은 왜 파란색인가요?라는 질문에 대한 답은 대기 중의 빛 산란 현상 때문입니다. 태양으로부터 오는 빛은 사실 모든 색깔을 포함하고 있는데, 이 빛이 지구 대기에 들어오면 대기 분자와 작은 입자들에 의해 산란됩니다. 이 과정에서 파란색 빛은 다른 색깔의 빛보다 더 많이 산란됩니다.\n",
      "\n",
      "이유는 파란색 빛의 파장이 상대적으로 짧기 때문입니다. 파장이 짧은 빛은 다른 색의 빛보다 산란되기 쉽습니다. 이러한 현상을 '레일리 산란'이라고 하며, 이로 인해 대기를 통과하는 동안 파란색 빛이 다른 색보다 더 효과적으로 산란되어 우리 눈에는 하늘이 파란색으로 보이게 됩니다.\n",
      "\n",
      "태양이 지평선에 가까울 때, 즉 일출이나 일몰 때에는 하늘이 빨강, 주황 또는 분홍색으로 보이는 경우가 있는데, 이는 태양 빛이 대기를 통과하는 거리가 더 길어지면서 파란색 빛이 더 많이 산란되고, 빨간색과 주황색 빛이 상대적으로 덜 산란되어 그 색이 더 강하게 나타나기 때문입니다.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T16:37:46.532344Z",
     "start_time": "2024-07-09T16:37:46.514571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 두 모델의 응답 평가를 위해 논문의 프롬프트 예시를 활용\n",
    "prompt = f\"\"\"\n",
    "[System]\n",
    "Please act as an impartial judge and evaluate the quality of the responses provided by two\n",
    "AI assistants to the user question displayed below. You should choose the assistant that\n",
    "follows the user’s instructions and answers the user’s question better. Your evaluation\n",
    "should consider factors such as the helpfulness, relevance, accuracy, depth, creativity,\n",
    "and level of detail of their responses. Begin your evaluation by comparing the two\n",
    "responses and provide a short explanation. Avoid any position biases and ensure that the\n",
    "order in which the responses were presented does not influence your decision. Do not allow\n",
    "the length of the responses to influence your evaluation. Do not favor certain names of\n",
    "the assistants. Be as objective as possible. After providing your explanation, output your\n",
    "final verdict by strictly following this format: \"[[A]]\" if assistant A is better, \"[[B]]\"\n",
    "if assistant B is better, and \"[[C]]\" for a tie.\n",
    "[User Question]\n",
    "{question}\n",
    "[The Start of Assistant A’s Answer]\n",
    "{answer_a}\n",
    "[The End of Assistant A’s Answer]\n",
    "[The Start of Assistant B’s Answer]\n",
    "{answer_b}\n",
    "[The End of Assistant B’s Answer]\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ],
   "id": "d7aa5a72497b3901",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[System]\n",
      "Please act as an impartial judge and evaluate the quality of the responses provided by two\n",
      "AI assistants to the user question displayed below. You should choose the assistant that\n",
      "follows the user’s instructions and answers the user’s question better. Your evaluation\n",
      "should consider factors such as the helpfulness, relevance, accuracy, depth, creativity,\n",
      "and level of detail of their responses. Begin your evaluation by comparing the two\n",
      "responses and provide a short explanation. Avoid any position biases and ensure that the\n",
      "order in which the responses were presented does not influence your decision. Do not allow\n",
      "the length of the responses to influence your evaluation. Do not favor certain names of\n",
      "the assistants. Be as objective as possible. After providing your explanation, output your\n",
      "final verdict by strictly following this format: \"[[A]]\" if assistant A is better, \"[[B]]\"\n",
      "if assistant B is better, and \"[[C]]\" for a tie.\n",
      "[User Question]\n",
      "하늘은 왜 파란색인가요?\n",
      "[The Start of Assistant A’s Answer]\n",
      "하늘이 파란색인 이유는 태양빛이 대기 중의 공기 분자들과 상호 작용하여 발생하는 현상 때문입니다. 태양빛은 다양한 색상의 빛으로 구성되어 있지만, 대기 중의 공기 분자들은 파란색 빛을 더 많이 흡수하고 다른 색상의 빛을 더 많이 반사합니다. 이러한 현상으로 인해 우리가 보는 하늘은 파란색으로 보이게 됩니다.\n",
      "[The End of Assistant A’s Answer]\n",
      "[The Start of Assistant B’s Answer]\n",
      "하늘은 왜 파란색인가요?라는 질문에 대한 답은 대기 중의 빛 산란 현상 때문입니다. 태양으로부터 오는 빛은 사실 모든 색깔을 포함하고 있는데, 이 빛이 지구 대기에 들어오면 대기 분자와 작은 입자들에 의해 산란됩니다. 이 과정에서 파란색 빛은 다른 색깔의 빛보다 더 많이 산란됩니다.\n",
      "\n",
      "이유는 파란색 빛의 파장이 상대적으로 짧기 때문입니다. 파장이 짧은 빛은 다른 색의 빛보다 산란되기 쉽습니다. 이러한 현상을 '레일리 산란'이라고 하며, 이로 인해 대기를 통과하는 동안 파란색 빛이 다른 색보다 더 효과적으로 산란되어 우리 눈에는 하늘이 파란색으로 보이게 됩니다.\n",
      "\n",
      "태양이 지평선에 가까울 때, 즉 일출이나 일몰 때에는 하늘이 빨강, 주황 또는 분홍색으로 보이는 경우가 있는데, 이는 태양 빛이 대기를 통과하는 거리가 더 길어지면서 파란색 빛이 더 많이 산란되고, 빨간색과 주황색 빛이 상대적으로 덜 산란되어 그 색이 더 강하게 나타나기 때문입니다.\n",
      "[The End of Assistant B’s Answer]\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T16:39:47.228771Z",
     "start_time": "2024-07-09T16:39:44.300905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 가장 최신 버전 gpt-4o로 각 모델들의 응답을 평가\n",
    "completion2 = client.chat.completions.create(\n",
    "    model = \"gpt-4o\",\n",
    "    messages = [{\"role\" : \"user\", \"content\" : prompt}],\n",
    "    temperature = 0\n",
    ")\n",
    "print(completion2.choices[0].message.content)"
   ],
   "id": "509b03f1c1adb0eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant A provides a concise explanation of why the sky is blue, mentioning the interaction of sunlight with air molecules and the selective absorption and reflection of blue light. However, the explanation is somewhat simplified and contains a minor inaccuracy: it states that air molecules absorb blue light more, which is not correct. The correct phenomenon is scattering, not absorption.\n",
      "\n",
      "Assistant B offers a more detailed and accurate explanation, correctly identifying Rayleigh scattering as the reason for the blue sky. It explains that blue light is scattered more due to its shorter wavelength. Additionally, Assistant B provides extra context by explaining why the sky appears red or orange during sunrise and sunset, which adds depth to the response.\n",
      "\n",
      "Considering the factors of accuracy, depth, and detail, Assistant B provides a more comprehensive and correct answer.\n",
      "\n",
      "Final verdict: [[B]]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 장단점 비교\n",
    "1. Human Based Method\n",
    "- 통제된 환경을 가정했을 때 사람이 직접 평가한 방법이라서 안정적이고 신뢰 가능함\n",
    "- 불특정 다수의 경우 약간의 응답 편차가 발생할 수 있음\n",
    "- 전문 분야의 경우 해당 전문가가 아닌 일반인이 평가할 경우 정확도 및 평가 속도가 낮아질 수 있음\n",
    "\n",
    "2. Model Based Evaluation\n",
    "- 사람의 평가와 어느 정도 유사한 수준의 판단을 내릴 수 있음\n",
    "- 평가를 위해 API 호출이 필요한데, 평가 데이터의 양이 굉장히 많을 경우 수 백만원 이상은 금방 넘어갈 수 있음\n",
    "\n",
    "3. Code Based Evaluation\n",
    "- 위 방법들에 비해 인력 비용, 모델 호출 비용 등이 없는 무료 평가 방법\n",
    "- Task에 따라 더 정확할 수도 있고, 그러지 않을 수도 있음\n",
    "- 사람에게 적합한 답변을 선택하는 데 있어서는 신뢰도가 상대적으로 떨어지는 편\n",
    "\n",
    "**실제 서비스의 관점에서 봤을 때 결국은 사용자의 피드백이 가장 중요하므로 상황에 따라 여러가지 기법들을 활용해 보는 것이 좋음**"
   ],
   "id": "58f75d95c39742cd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 프롬프트 엔지니어링 고도화 기법\n",
    "1. Few-shot\n",
    "   - 참고할 수 있는 질의/응답 예시나 사례들을 프롬프트에 추가하여 질의\n",
    "2. Chain-of-thought\n",
    "   - 모델에게 문제 해결 과정을 단계 별로 알려주면서 질의 (보통 Few-shot과 함께 사용)"
   ],
   "id": "a0677c42c5068d73"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Few-shot",
   "id": "ca7b2296d2ea6919"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T16:45:28.381001Z",
     "start_time": "2024-07-09T16:45:27.456559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# zero-shot\n",
    "prompt = \"\"\"Q : Who wrote the book 'HARRY POTTER'?\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [{\"role\" : \"user\", \"content\" : prompt}],\n",
    "    temperature = 0\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ],
   "id": "3eef4eb3aefd7121",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J.K. Rowling wrote the book 'Harry Potter'.\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T16:46:25.998554Z",
     "start_time": "2024-07-09T16:46:25.090158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# one-shot\n",
    "prompt = \"\"\"\n",
    "Answer these questions :\n",
    "Q : Who wrote the book 'HARRY POTTER'?\n",
    "\n",
    "Below is an example for your reference.\n",
    "Q : Who sang 'One Call Away'?\n",
    "A : Charlie Puth\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [{\"role\" : \"user\", \"content\" : prompt}],\n",
    "    temperature = 0\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ],
   "id": "45ec02b02f409797",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q : Who wrote the book 'HARRY POTTER'?\n",
      "A : J.K. Rowling\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- 우리가 제시해 준 예시를 잘 참고하여 질문에 대해 대답하는 것을 확인할 수 있음",
   "id": "8aea16d86ff8523a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. Chain-of-thought\n",
    "- 마이크로소프트에서 활용한 예시 프롬프트를 사용"
   ],
   "id": "f91fee261932e51"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T16:49:38.176582Z",
     "start_time": "2024-07-09T16:49:36.933787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Base 프롬프트로 진행\n",
    "prompt = \"\"\"Alice has 5 apples, throws 3 apples, gives 2 to Bob and Bob gives one back, how many apples does Alice have?\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [{\"role\" : \"user\", \"content\" : prompt}],\n",
    "    temperature = 0\n",
    ")\n",
    "print(completion.choices[0].message.content)\n",
    "# 정답은 1개여야 하는데 5개로 잘못 계산함"
   ],
   "id": "f6dd5c557a66fa44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice would have 5 apples - 3 thrown + 2 given to Bob + 1 received from Bob = 5 apples. \n",
      "\n",
      "So, Alice still has 5 apples.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### CoT + one-shot",
   "id": "1fc80c932000a217"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T16:51:51.954623Z",
     "start_time": "2024-07-09T16:51:50.626783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = \"\"\"\n",
    "Alice has 5 apples, throws 3 apples, gives 2 to Bob and Bob gives one back, how many apples does Alice have?\n",
    "Below is an example for your reference.\n",
    "Lisa has 7 apples, throw 1 apple. give 4 apples to Bart and Bart gives one back :\n",
    "7 - 1 = 6\n",
    "6 - 4 = 2\n",
    "2 + 1 = 3\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [{\"role\" : \"user\", \"content\" : prompt}],\n",
    "    temperature = 0\n",
    ")\n",
    "print(completion.choices[0].message.content) # 드디어 정답"
   ],
   "id": "fec21c08137eab19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice has 5 apples - 3 thrown = 2 apples\n",
      "2 apples - 2 given to Bob = 0 apples\n",
      "Bob gives 1 apple back, so Alice now has 0 + 1 = 1 apple.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T16:52:47.874209Z",
     "start_time": "2024-07-09T16:52:44.859625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = \"\"\"Alice has 5 apples, throws 3 apples, gives 2 to Bob and Bob gives one back, how many apples does Alice have?\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "    model = \"gpt-4o\",\n",
    "    messages = [{\"role\" : \"user\", \"content\" : prompt}],\n",
    "    temperature = 0\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ],
   "id": "7135fcd117d1f7b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's break down the sequence of events to determine how many apples Alice has:\n",
      "\n",
      "1. Alice starts with 5 apples.\n",
      "2. Alice throws 3 apples. (Assuming these apples are no longer in her possession)\n",
      "   - Apples left: 5 - 3 = 2 apples\n",
      "3. Alice gives 2 apples to Bob.\n",
      "   - Apples left: 2 - 2 = 0 apples\n",
      "4. Bob gives one apple back to Alice.\n",
      "   - Apples left: 0 + 1 = 1 apple\n",
      "\n",
      "So, after all these transactions, Alice has 1 apple.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 또 다른 프롬프트 고도화 예시\n",
    "- KMMLU 논문의 예시 프롬프트 템플릿 사용"
   ],
   "id": "786394f75287a0a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T16:54:55.502192Z",
     "start_time": "2024-07-09T16:54:55.487783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 실제 정답은 B = 6\n",
    "question = \"x, y가 세 부등식 y ≤ x+3, y ≤ -4x+3, y ≥ 0을 만족할 때, x+y의 최댓 값을 M, 최솟 값을 m이라 하면 M-m의 값은?\"\n",
    "A = 4\n",
    "B = 6\n",
    "C = 8\n",
    "D = 10"
   ],
   "id": "3eb0a6940b87d7c2",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T16:54:56.645203Z",
     "start_time": "2024-07-09T16:54:55.833354Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = f\"\"\"\n",
    "{question}\n",
    "A. {A}\n",
    "B. {B}\n",
    "C. {C}\n",
    "D. {D}\n",
    "정답：\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [{\"role\" : \"user\", \"content\" : prompt}],\n",
    "    temperature = 0\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ],
   "id": "b09f85cd9eb411e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C. 8\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T16:55:55.926414Z",
     "start_time": "2024-07-09T16:55:42.946295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = f\"\"\"\n",
    "{question}\n",
    "A. {A}\n",
    "B. {B}\n",
    "C. {C}\n",
    "D. {D}\n",
    "정답：\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "    model = \"gpt-4o\",\n",
    "    messages = [{\"role\" : \"user\", \"content\" : prompt}],\n",
    "    temperature = 0\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ],
   "id": "86d03dc2323be3f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "주어진 부등식들을 분석하여 \\(x\\)와 \\(y\\)의 범위를 찾아보겠습니다.\n",
      "\n",
      "1. \\(y \\leq x + 3\\)\n",
      "2. \\(y \\leq -4x + 3\\)\n",
      "3. \\(y \\geq 0\\)\n",
      "\n",
      "이 세 부등식을 만족하는 영역을 구하기 위해 각 부등식의 경계선을 그려보겠습니다.\n",
      "\n",
      "1. \\(y = x + 3\\)\n",
      "2. \\(y = -4x + 3\\)\n",
      "3. \\(y = 0\\)\n",
      "\n",
      "이 세 직선이 만나는 점들을 찾아보겠습니다.\n",
      "\n",
      "1. \\(y = x + 3\\)와 \\(y = -4x + 3\\)의 교점을 구합니다.\n",
      "   \\[\n",
      "   x + 3 = -4x + 3 \\implies 5x = 0 \\implies x = 0\n",
      "   \\]\n",
      "   \\[\n",
      "   y = 0 + 3 = 3\n",
      "   \\]\n",
      "   따라서 교점은 \\((0, 3)\\)입니다.\n",
      "\n",
      "2. \\(y = x + 3\\)와 \\(y = 0\\)의 교점을 구합니다.\n",
      "   \\[\n",
      "   0 = x + 3 \\implies x = -3\n",
      "   \\]\n",
      "   따라서 교점은 \\((-3, 0)\\)입니다.\n",
      "\n",
      "3. \\(y = -4x + 3\\)와 \\(y = 0\\)의 교점을 구합니다.\n",
      "   \\[\n",
      "   0 = -4x + 3 \\implies 4x = 3 \\implies x = \\frac{3}{4}\n",
      "   \\]\n",
      "   따라서 교점은 \\(\\left(\\frac{3}{4}, 0\\right)\\)입니다.\n",
      "\n",
      "이제 이 세 점 \\((0, 3)\\), \\((-3, 0)\\), \\(\\left(\\frac{3}{4}, 0\\right)\\)을 이용하여 \\(x + y\\)의 값을 계산해보겠습니다.\n",
      "\n",
      "1. \\((0, 3)\\)에서 \\(x + y = 0 + 3 = 3\\)\n",
      "2. \\((-3, 0)\\)에서 \\(x + y = -3 + 0 = -3\\)\n",
      "3. \\(\\left(\\frac{3}{4}, 0\\right)\\)에서 \\(x + y = \\frac{3}{4} + 0 = \\frac{3}{4}\\)\n",
      "\n",
      "따라서 \\(x + y\\)의 최댓값은 3이고, 최솟값은 -3입니다. \\(M - m\\)을 계산하면:\n",
      "\\[\n",
      "M - m = 3 - (-3) = 6\n",
      "\\]\n",
      "\n",
      "정답은 B. 6입니다.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### GPT-3.5 모델 고도화 작업\n",
    "- 페르소나 적용 + 영문으로 프롬프트 작성"
   ],
   "id": "fd7794fe9b569ac2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T16:57:14.534887Z",
     "start_time": "2024-07-09T16:57:14.044226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = f\"\"\"\n",
    "You are a Professional in Mathmatics. Below id given a math question in Korean.\n",
    "{question}\n",
    "A. {A}\n",
    "B. {B}\n",
    "C. {C}\n",
    "D. {D}\n",
    "Answer：\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [{\"role\" : \"user\", \"content\" : prompt}],\n",
    "    temperature = 0\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ],
   "id": "296cd6b091e158fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C. 8\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Chain of Thought 적용",
   "id": "335e36814e3ee3bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T16:58:54.333273Z",
     "start_time": "2024-07-09T16:58:47.710247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = f\"\"\"\n",
    "You are a Professional in Mathmatics. Below id given a math question in Korean.\n",
    "You have to think carefully and step by step about the question and choose one of four given answer.\n",
    "Only one of them is true.\n",
    "\n",
    "{question}\n",
    "A. {A}\n",
    "B. {B}\n",
    "C. {C}\n",
    "D. {D}\n",
    "Answer：\n",
    "\"\"\"\n",
    "completion = client.chat.completions.create(\n",
    "    model = \"gpt-3.5-turbo\",\n",
    "    messages = [{\"role\" : \"user\", \"content\" : prompt}],\n",
    "    temperature = 0\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ],
   "id": "968b746a40a955b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B. 6\n",
      "\n",
      "To find the maximum and minimum values of x+y, we need to find the intersection points of the three inequalities.\n",
      "\n",
      "First, let's find the intersection points of y ≤ x+3 and y ≤ -4x+3:\n",
      "x+3 = -4x+3\n",
      "5x = 0\n",
      "x = 0\n",
      "\n",
      "When x = 0, y = 3\n",
      "\n",
      "So, the intersection point of these two inequalities is (0, 3).\n",
      "\n",
      "Next, let's find the intersection points of y ≤ x+3 and y ≥ 0:\n",
      "x+3 = 0\n",
      "x = -3\n",
      "\n",
      "When x = -3, y = 0\n",
      "\n",
      "So, the intersection point of these two inequalities is (-3, 0).\n",
      "\n",
      "Now, let's find the intersection points of y ≤ -4x+3 and y ≥ 0:\n",
      "-4x+3 = 0\n",
      "-4x = -3\n",
      "x = 3/4\n",
      "\n",
      "When x = 3/4, y = 0\n",
      "\n",
      "So, the intersection point of these two inequalities is (3/4, 0).\n",
      "\n",
      "Now, we have three intersection points: (0, 3), (-3, 0), and (3/4, 0).\n",
      "\n",
      "To find the maximum value of x+y, we need to find the point that is farthest from the origin, which is (0, 3). So, the maximum value of x+y is 3.\n",
      "\n",
      "To find the minimum value of x+y, we need to find the point that is closest to the origin, which is (-3, 0). So, the minimum value of x+y is -3.\n",
      "\n",
      "Therefore, M-m = 3 - (-3) = 6. So, the correct answer is B. 6.\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- gpt-3.5-turbo의 경우, CoT까지 적용을 하니 정답을 맞추는 것을 볼 수 있음\n",
    "- 4o 모델의 경우 zero-shot으로도 좋은 성능을 내는 것을 볼 수 있지만, 비용 측면에서는 3.5 모델이 10배 정도 저렴하기 때문에 이런 부분을 고려하여 3.5 모델에서 프롬프트를 고도화 시키는 작업이 선행 되어야 함"
   ],
   "id": "bf56ddceda3ec9b2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 💡 프롬프트 엔지니어링 정리\n",
    "- 추가 학습이 없어도 성능 개선의 가능성이 있기 때문에 가성비가 굉장히 좋음\n",
    "- 더 좋은 모델을 사용하면 프롬프트 엔지니어링 없이도 해결되는 케이스들이 다수 존재\n",
    "- 그러나 모델의 알고리즘이 완전히 바뀌게 되면 기존에 사용했던 프롬프팅 방식들이 달라질 수 있음 (변동성 up)\n",
    "- 프롬프트 엔지니어링은 모델의 응답 성능을 높일 수 있는 수많은 방법론 중 하나이며, 처음에는 프롬프트 엔지니어링으로 성능 향상을 시도해 보고 부족하면 RAG, Fine-tuning과 같은 순서로 다른 방법을 시도해 볼 수 있음"
   ],
   "id": "b951fd605b868e7a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
